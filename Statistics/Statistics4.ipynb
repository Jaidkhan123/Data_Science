{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0ec9a5",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b86be0",
   "metadata": {},
   "source": [
    "`Probability Mass Function (PMF)` and `Probability Density Function (PDF)` are two fundamental concepts in probability theory and statistics.\n",
    "\n",
    "`PMF` is used to describe the probability distribution of a discrete random variable. It is a function that gives the probability of each possible value that the random variable can take. The sum of probabilities of all possible values is equal to one.\n",
    "\n",
    "`For example`, let's consider a fair six-sided die. The PMF of this die is given by:\n",
    "\n",
    "- x\t         1, 2,\t3,\t4,\t5,\t6\n",
    "- P(X=x)\t1/6,\t1/6,\t1/6,\t1/6,\t1/6,\t1/6\n",
    "\n",
    "Here, X is the random variable that represents the outcome of rolling the die. The `PMF` of X shows that the probability of getting any number between 1 and 6 is 1/6.\n",
    "\n",
    "`PDF`, on the other hand, is used to describe the probability distribution of a continuous random variable. It is a function that gives the relative likelihood of the random variable taking on a particular value within a given range. The total area under the PDF curve equals one.\n",
    "\n",
    "`For example`, let's consider the standard normal distribution with mean 0 and standard deviation 1. The PDF of this distribution is given by:\n",
    "\n",
    "-  $ f(x) = \\frac{1}{\\sqrt{2π}}  e^{\\frac{-x^2}{2}} $\n",
    "\n",
    "Here, f(x) represents the probability density function of the standard normal distribution. The function shows that the probability of getting any specific value of x is very small, but the likelihood of getting values within a certain range is relatively high. The area under the curve between any two values represents the probability of getting a value within that range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca75f2",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06634926",
   "metadata": {},
   "source": [
    "`Cumulative Distribution Function (CDF)` is a function that describes the probability that a random variable takes a value less than or equal to a given value. It is defined as the integral of the `Probability Density Function (PDF)` for a continuous random variable, or as the sum of the `Probability Mass Function (PMF)` for a discrete random variable.\n",
    "\n",
    "For a random variable X, the CDF is denoted by F(x), and it is given by:\n",
    "\n",
    "- $ F(x) = P(X ≤ x) $\n",
    "\n",
    "In other words, F(x) gives the probability that the random variable X takes on a value less than or equal to x.\n",
    "\n",
    "For example, let's consider the standard normal distribution with mean $\\theta$ and standard deviation 1. The CDF of this distribution is denoted by $\\phi(x)$, and it is given by:\n",
    "\n",
    " $\\phi(x)= \\int_x^\\infty \\frac{1}{\\sqrt{2π}}  e^{\\frac{-x^2}{2}}) dt $\n",
    "\n",
    "Here, $\\phi(x)$ represents the probability that a random variable X that follows the standard normal distribution takes on a value less than or equal to x.\n",
    "\n",
    "The CDF is useful because it provides a way to calculate the probability of getting a value less than or equal to a given value, without needing to calculate the probability density function or probability mass function for each value. It also allows us to calculate the probability of getting a value within a range of values by taking the difference of the CDF values at the upper and lower bounds of the range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42256c0f",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13400d14",
   "metadata": {},
   "source": [
    "The `normal distribution`, also known as the `Gaussian distribution`, is a probability distribution that is commonly used as a model for a wide range of natural phenomena and data sets in many different fields, such as physics, engineering, social sciences, and finance. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "- 1. Heights of individuals in a population\n",
    "- 2. Weights of objects produced by a factory\n",
    "- 3. IQ scores in a population\n",
    "- 4. Test scores in a large class\n",
    "- 5. Lengths of fish in a lake\n",
    "- 6. Blood pressure readings in a population\n",
    "\n",
    "The normal distribution is characterized by two parameters:` the mean (μ)` and the `standard deviation (σ)`. The mean represents the center of the distribution, while the standard deviation represents the spread or variability of the distribution.\n",
    "\n",
    "The shape of the normal distribution is determined by these two parameters. Specifically, the mean determines the location of the peak of the distribution, while the standard deviation determines the width of the distribution. A larger standard deviation corresponds to a wider distribution with more spread-out values, while a smaller standard deviation corresponds to a narrower distribution with values clustered more tightly around the mean.\n",
    "\n",
    "Additionally, the normal distribution is symmetric around the mean, meaning that the probability of obtaining a value above the mean is the same as the probability of obtaining a value below the mean. The total area under the curve of the normal distribution is equal to 1, meaning that the probability of obtaining any value within the distribution is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d8348",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ccca6",
   "metadata": {},
   "source": [
    "The normal distribution is an important and widely used probability distribution in statistics and data analysis. It is also known as the Gaussian distribution, after the mathematician Carl Friedrich Gauss who first described it. Some of the reasons for its importance are:\n",
    "\n",
    "- 1. It is a versatile distribution that can be used to model a wide range of phenomena in many different fields. This includes physical measurements such as height, weight, and length, as well as cognitive measurements such as IQ scores and test scores.\n",
    "\n",
    "- 2. Many statistical methods rely on the assumption that the data follows a normal distribution, including hypothesis testing, confidence interval estimation, and linear regression analysis.\n",
    "\n",
    "- 3. It has a well-defined mathematical form and known properties, which allows for easy calculation of probabilities, means, and variances.\n",
    "\n",
    "- 4. The central limit theorem states that the sum of many independent and identically distributed random variables tends to follow a normal distribution, regardless of the underlying distribution of the individual variables. This makes the normal distribution a natural choice for modeling the sum or average of a large number of random variables.\n",
    "\n",
    "**Some real-life examples of normal distribution include:**\n",
    "\n",
    "- 1. `Heights of people in a population`: The distribution of heights of people in a given population is often modeled by a normal distribution, with the mean and standard deviation varying by age and gender.\n",
    "\n",
    "- 2. `Weights of objects produced by a factory`: The distribution of weights of objects produced by a factory can often be approximated by a normal distribution, with the mean representing the expected weight and the standard deviation representing the variability in weights.\n",
    "\n",
    "- 3. `IQ scores in a population`: The distribution of IQ scores in a population is often modeled by a normal distribution, with the mean representing the average IQ score and the standard deviation representing the variability in scores.\n",
    "\n",
    "- 4. `Test scores in a large class`: The distribution of test scores in a large class can often be approximated by a normal distribution, with the mean representing the average score and the standard deviation representing the variability in scores.\n",
    "\n",
    "- 5. `Blood pressure readings in a population`: The distribution of blood pressure readings in a population can often be modeled by a normal distribution, with the mean representing the expected blood pressure and the standard deviation representing the variability in readings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553d645",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0701a",
   "metadata": {},
   "source": [
    "`The Bernoulli distribution` is a discrete probability distribution that represents the outcome of a single binary event with probability of success (often denoted as \"p\") and probability of failure (often denoted as \"1-p\"). The distribution takes on the value of 1 with probability p and the value of 0 with probability (1-p).\n",
    "\n",
    "- `For example`, flipping a coin can be modeled as a Bernoulli distribution, where p represents the probability of getting heads and 1-p represents the probability of getting tails. Another example is rolling a die and observing whether a particular number comes up or not.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models a single binary event while the binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. In other words, the binomial distribution is the sum of independent and identically distributed Bernoulli random variables.\n",
    "\n",
    "- `For example`, rolling a die 10 times and counting the number of times a particular number comes up can be modeled using a binomial distribution. In this case, each roll of the die is an independent Bernoulli trial, and the binomial distribution represents the number of successes (i.e., the number of times the particular number comes up) in the 10 trials.\n",
    "\n",
    "The binomial distribution has two parameters: `the number of trials (n)` and the `probability of success (p)`. The mean of the binomial distribution is np and the variance is np(1-p). As the number of trials increases, the binomial distribution approaches a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f294e7f",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc409e02",
   "metadata": {},
   "source": [
    "To solve this problem, we can use the standard normal distribution and the Z-score formula:\n",
    "\n",
    "   $$Z = \\frac{(X - \\mu)}{\\sigma} $$\n",
    "\n",
    "where X is the observation we are interested in, $\\mu$ is the mean of the distribution,$\\sigma$ is the standard deviation of the distribution, and Z is the corresponding Z-score.\n",
    "\n",
    "In this case, we have:\n",
    "\n",
    "X = 60\n",
    "$\\mu$ = 50\n",
    "$\\sigma$= 10\n",
    "\n",
    "Using the formula, we can calculate the Z-score:\n",
    "\n",
    " $$Z = \\frac{(X - \\mu)}{\\sigma} = \\frac{(60- 50)}{10} = 1$$\n",
    "\n",
    "The Z-score tells us how many standard deviations away from the mean the observation is. A Z-score of 1 means that the observation is 1 standard deviation above the mean.\n",
    "\n",
    "`Next`, we need to find the area under the standard normal distribution curve to the right of the Z-score. We can use a Z-table or a calculator to find this area. For example, using a calculator, we can use the standard normal distribution function (norm.dist) with a mean of 0 and a standard deviation of 1, and set the cumulative parameter to TRUE to get the area to the right of the Z-score:\n",
    "\n",
    "- P(Z > 1) = 1 - norm.dist(1, 0, 1, TRUE) = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06acaf",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3aef9",
   "metadata": {},
   "source": [
    "`Uniform distribution` is a continuous probability distribution where all outcomes have equal probability. In other words, it is a probability distribution where each value within a specified range is equally likely to occur.\n",
    "\n",
    "- `For example`, rolling a fair six-sided die can be modeled using a uniform distribution, where each of the six possible outcomes (1, 2, 3, 4, 5, 6) has an equal probability of occurring.\n",
    "\n",
    "Another example of uniform distribution is the distribution of random numbers generated by a computer program or a calculator, where each number between 0 and 1 (or any other specified range) is equally likely to occur.\n",
    "\n",
    "In a uniform distribution, the probability density function is constant within the specified range and zero outside that range. The mean of a uniform distribution is the average of the minimum and maximum values in the range, and the variance is given by $\\frac{(b-a)^2}{12}$, where a and b are the minimum and maximum values in the range, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a4cdc",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882c233",
   "metadata": {},
   "source": [
    "A `Z-score`, also known as a `standard score`, is a measure of how many standard deviations an observation or data point is from the mean of the distribution. It is calculated by subtracting the mean from the observation and dividing by the standard deviation:\n",
    "\n",
    "$$ Z = \\frac{(X - \\mu)}{\\sigma }  $$\n",
    "\n",
    "where Z is the `Z-scor`, X is the observation or data point, $\\mu$ is the mean of the distribution, and $\\sigma$ is the standard deviation of the distribution.\n",
    "\n",
    "The Z-score is important because it allows us to compare observations or data points from different distributions that may have different units or scales. By converting each observation or data point to a Z-score, we can standardize the data and compare them on a common scale.\n",
    "\n",
    "- `For example`, if we are comparing the test scores of two different classes, where one class had a mean score of 75 and a standard deviation of 10, and the other class had a mean score of 85 and a standard deviation of 15, we cannot compare the raw scores directly because they are on different scales. However, by converting each score to a Z-score using the appropriate mean and standard deviation, we can compare the scores on a common scale and determine which class performed relatively better or worse.\n",
    "\n",
    "- The Z-score is also used in hypothesis testing, where we compare the Z-score of a sample to a critical value from a standard normal distribution to determine whether the sample is significantly different from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180452c9",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0554dec",
   "metadata": {},
   "source": [
    "The `Central Limit Theorem (CLT)` is a statistical theory that states that as the sample size of a random sample drawn from any population increases, the distribution of the sample means will approach a normal distribution, regardless of the shape of the population distribution.\n",
    "\n",
    "`In other words`, the Central Limit Theorem states that if we take many random samples from any population and calculate the mean of each sample, the distribution of those sample means will be approximately normal, even if the original population distribution is not normal. This applies to both discrete and continuous populations.\n",
    "\n",
    "`The significance of the Central Limit Theorem` is that it provides a basis for using normal distribution-based statistical techniques on sample means, even if the original population distribution is not normal. This is important because many statistical tests and confidence intervals are based on the assumption of normality.\n",
    "\n",
    "- `For example`, if we want to estimate the mean height of all people in a country, we can take a random sample of people and calculate the mean height of that sample. By the Central Limit Theorem, the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution of heights. We can then use this normal distribution to calculate a confidence interval for the true population mean height, or to conduct a hypothesis test about the population mean height.\n",
    "\n",
    "- The Central Limit Theorem is also important because it is widely used in quality control, market research, and other fields that require the analysis of large amounts of data. By relying on the Central Limit Theorem, researchers and analysts can use statistical methods with confidence, even when working with non-normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9457cc31",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8c962",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) makes certain assumptions about the underlying population in order to hold true. These assumptions include:\n",
    "\n",
    "- 1. `The population must be random`: The observations in the population must be selected randomly or at least assumed to be so.\n",
    "\n",
    "- 2. `The sample size must be sufficiently large`: The sample size should be large enough such that the sample mean has a normal distribution, regardless of the shape of the population distribution.\n",
    "\n",
    "- 3. `The sample must be independent`: Each observation in the sample must be independent of each other observation.\n",
    "\n",
    "- 4. `The population must have a finite variance`: The population from which the sample is drawn must have a finite variance.\n",
    "\n",
    "If these assumptions are met, the Central Limit Theorem states that the distribution of the sample means will approach a normal distribution, regardless of the shape of the population distribution. However, if any of these assumptions are violated, the Central Limit Theorem may not hold, and alternative methods may need to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61049edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b19bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
